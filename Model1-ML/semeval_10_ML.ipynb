{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "enEzufdHNndZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dhana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dhana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "J7qRdnuTOq_E"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change your file path here\n",
    "filepath = os.path.join(os.path.curdir, \"data\", \"train_all_tasks.csv\")\n",
    "df = pd.read_csv(filepath)\n",
    "df = df.drop(columns=['rewire_id'])\n",
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1wg5yQOPNkr"
   },
   "source": [
    "#**TASK-A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Wr1TnmHcPEEE"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'www\\S+', '', text) \n",
    "    text = re.sub(r'<.*?>', '', text)  \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub('\\s+', ' ', text) \n",
    "    return text\n",
    "\n",
    "def remove_stopword(text, stopwords):\n",
    "    return \" \".join([word for word in text.split() if word not in (stop_words)])\n",
    "\n",
    "def lemma_text(text, lemmatizer):\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in tokenize(text)]\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "def process_text(text, lemmatizer, stop_words):\n",
    "    text = clean_text(text)\n",
    "    text = remove_stopword(text, stop_words)\n",
    "    text = lemma_text(text, lemmatizer)\n",
    "    return text \n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rVRwwE_FQXyj"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>label_category</th>\n",
       "      <th>label_vector</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Damn, this writing was pretty chaotic</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>damn writing pretty chaotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah, and apparently a bunch of misogynistic v...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>yeah apparently bunch misogynistic virgin one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How the FUCK is this woman still an MP!!!???</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>fuck woman still mp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understand. Know you're right. At same time I ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>understand know youre right time know isnt eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surprized they didn't stop and rape some women</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>surprized didnt stop rape woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label_sexist  \\\n",
       "0              Damn, this writing was pretty chaotic   not sexist   \n",
       "1  Yeah, and apparently a bunch of misogynistic v...   not sexist   \n",
       "2       How the FUCK is this woman still an MP!!!???   not sexist   \n",
       "3  Understand. Know you're right. At same time I ...   not sexist   \n",
       "4     Surprized they didn't stop and rape some women   not sexist   \n",
       "\n",
       "  label_category label_vector  \\\n",
       "0           none         none   \n",
       "1           none         none   \n",
       "2           none         none   \n",
       "3           none         none   \n",
       "4           none         none   \n",
       "\n",
       "                                      processed_text  \n",
       "0                        damn writing pretty chaotic  \n",
       "1  yeah apparently bunch misogynistic virgin one ...  \n",
       "2                                fuck woman still mp  \n",
       "3  understand know youre right time know isnt eno...  \n",
       "4                    surprized didnt stop rape woman  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"processed_text\"] = df['text'].apply(process_text, lemmatizer = lemmatizer, stop_words = stop_words)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PIadfqYPwgVI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_s: (3398, 5)\n",
      "class_ns: (10602, 5)\n"
     ]
    }
   ],
   "source": [
    "#Under sampling the data\n",
    "# class count\n",
    "class_notsexist, class_sexist = df['label_sexist'].value_counts()\n",
    "class_notsexist, class_sexist\n",
    "# # Separate class\n",
    "class_s = df[df['label_sexist'] == \"sexist\"]\n",
    "class_ns = df[df['label_sexist'] == \"not sexist\"]\n",
    "print('class_s:', class_s.shape)\n",
    "print('class_ns:', class_ns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gJWa9p0dxeFY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'count (target)'}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_ns_under = class_ns.sample(class_sexist+1000)\n",
    "\n",
    "df_under = pd.concat([class_ns_under, class_s], axis=0)\n",
    "df_under['label_sexist'].value_counts().plot(kind='bar', title='count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eWf2wKxlSyuS"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_text_vec = tfidf.fit_transform(df_under.processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kEpdqHIQTVYq"
   },
   "outputs": [],
   "source": [
    "x_train_a, x_test_a, y_train_a, y_test_a = train_test_split(tfidf_text_vec, df_under['label_sexist'], test_size=0.2, train_size=0.8, random_state=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwmdeRIpcby6"
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "crPbwzYTT4hs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.65%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.71      0.89      0.79       883\n",
      "      sexist       0.79      0.54      0.64       677\n",
      "\n",
      "    accuracy                           0.74      1560\n",
      "   macro avg       0.75      0.71      0.72      1560\n",
      "weighted avg       0.75      0.74      0.73      1560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrm = LogisticRegression(penalty='l2', random_state=0).fit(x_train_a, y_train_a)\n",
    "lrm_pred = lrm.predict(x_test_a)\n",
    "acc = accuracy_score(lrm_pred, y_test_a)\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_a, lrm_pred))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_a, lrm_pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result\", \"task_a_cls_report_logistic_reg.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPOsqnVOcghA"
   },
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "H-zBK9hqUCQc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.19%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.64      0.68      0.66       883\n",
      "      sexist       0.54      0.51      0.52       677\n",
      "\n",
      "    accuracy                           0.60      1560\n",
      "   macro avg       0.59      0.59      0.59      1560\n",
      "weighted avg       0.60      0.60      0.60      1560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_clf = tree.DecisionTreeClassifier(criterion='entropy', max_features=20)\n",
    "dt_clf.fit(x_train_a, y_train_a)\n",
    "pred = dt_clf.predict(x_test_a)\n",
    "acc = accuracy_score(pred, y_test_a)\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_a, pred))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_a, pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result\", \"task_a_cls_report_logistic_decision_tree.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNXYgqcp4-0I"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_A-aZyLcjp-"
   },
   "source": [
    "**Xgboost Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_a_enc = le.fit_transform(y_train_a)\n",
    "y_test_a_enc = le.fit_transform(y_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3ICpw9UIU5bB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.29%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.79       883\n",
      "           1       0.74      0.63      0.68       677\n",
      "\n",
      "    accuracy                           0.74      1560\n",
      "   macro avg       0.74      0.73      0.73      1560\n",
      "weighted avg       0.74      0.74      0.74      1560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=5)\n",
    "xgb_model.fit(x_train_a, y_train_a_enc)\n",
    "\n",
    "y_pred = xgb_model.predict(x_test_a)\n",
    "y_pred_enc = le.fit_transform(y_pred)\n",
    "\n",
    "acc = accuracy_score(y_pred_enc, y_test_a_enc)\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_a_enc, y_pred_enc))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_a_enc, y_pred_enc, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result\", \"task_a_cls_report_xgboost.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "__QsvxECqpBP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.09%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.75      0.86      0.80       883\n",
      "      sexist       0.78      0.63      0.70       677\n",
      "\n",
      "    accuracy                           0.76      1560\n",
      "   macro avg       0.76      0.75      0.75      1560\n",
      "weighted avg       0.76      0.76      0.76      1560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier().fit(x_train_a, y_train_a)\n",
    "rf_pred = rf_clf.predict(x_test_a)\n",
    "acc = accuracy_score(rf_pred, y_test_a)\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_a, rf_pred))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_a, rf_pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result\", \"task_a_cls_report_random_forest.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnIGherpcPPl"
   },
   "source": [
    "#**TASK-B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0h330eVITELO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3398"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b = df[df['label_category'] != 'none']\n",
    "df = df_b\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vOr2UKKhcyWq"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_text_vec = tfidf.fit_transform(df.processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-CWLq0socSOU"
   },
   "outputs": [],
   "source": [
    "x_train_b, x_test_b, y_train_b, y_test_b = train_test_split(tfidf_text_vec, df['label_category'], test_size=0.2, train_size=0.8, random_state=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-l7vMb0A5mq0"
   },
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WrA-NwA1c6jC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.59%\n",
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "1. threats, plans to harm and incitement       0.26      0.15      0.19        65\n",
      "                           2. derogation       0.52      0.59      0.55       321\n",
      "                            3. animosity       0.43      0.42      0.42       230\n",
      "               4. prejudiced discussions       0.27      0.23      0.25        64\n",
      "\n",
      "                                accuracy                           0.46       680\n",
      "                               macro avg       0.37      0.35      0.36       680\n",
      "                            weighted avg       0.44      0.46      0.45       680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_clf = tree.DecisionTreeClassifier()\n",
    "dt_clf.fit(x_train_b, y_train_b)\n",
    "pred = dt_clf.predict(x_test_b)\n",
    "acc = accuracy_score(pred, y_test_b)\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_b, pred))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_b, pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result\", \"task_b_cls_report_decision_tree.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_b_enc = le.fit_transform(y_train_b)\n",
    "y_test_b_enc = le.fit_transform(y_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvrAer4a5rzY"
   },
   "source": [
    "**Xgboost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bIU43CyXdGBi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.38%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.17      0.27        65\n",
      "           1       0.51      0.72      0.60       321\n",
      "           2       0.42      0.33      0.37       230\n",
      "           3       0.42      0.16      0.23        64\n",
      "\n",
      "    accuracy                           0.48       680\n",
      "   macro avg       0.49      0.34      0.37       680\n",
      "weighted avg       0.48      0.48      0.45       680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=5)\n",
    "xgb_model.fit(x_train_b, y_train_b_enc)\n",
    "\n",
    "y_pred = xgb_model.predict(x_test_b)\n",
    "y_pred_enc = le.fit_transform(y_pred)\n",
    "\n",
    "acc = accuracy_score(y_pred_enc, y_test_b_enc)\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_b_enc, y_pred_enc))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_b_enc, y_pred_enc, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result\", \"task_b_cls_report_xgboost.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7Ol5uZ05wYa"
   },
   "source": [
    "**RandomForest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sm5usix7rEs1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.21%\n",
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "1. threats, plans to harm and incitement       0.00      0.00      0.00        65\n",
      "                           2. derogation       0.47      1.00      0.64       321\n",
      "                            3. animosity       0.00      0.00      0.00       230\n",
      "               4. prejudiced discussions       0.00      0.00      0.00        64\n",
      "\n",
      "                                accuracy                           0.47       680\n",
      "                               macro avg       0.12      0.25      0.16       680\n",
      "                            weighted avg       0.22      0.47      0.30       680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=3, random_state=5).fit(x_train_b, y_train_b)\n",
    "rf_pred = rf_clf.predict(x_test_b)\n",
    "acc = accuracy_score(rf_pred, y_test_b)\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_b, rf_pred))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_b, rf_pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result\", \"task_b_cls_report_random_forest.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZFruibVdcpi"
   },
   "source": [
    "#**TASK-C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gBbFb7jWUSOl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3398"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c = df[df['label_vector'] != 'none']\n",
    "df = df_c\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9MCdvo1Vc6z6"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_text_vec = tfidf.fit_transform(df.processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "in_9x5JkdcQ3"
   },
   "outputs": [],
   "source": [
    "x_train_c, x_test_c, y_train_c, y_test_c = train_test_split(tfidf_text_vec, df['label_vector'], test_size=0.2, train_size=0.8, random_state=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9uKBkyJ569m"
   },
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Owknt221d-ZE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 36.18%\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm       0.00      0.00      0.00         9\n",
      "                       1.2 incitement and encouragement of harm       0.38      0.38      0.38        56\n",
      "                                        2.1 descriptive attacks       0.38      0.48      0.43       139\n",
      "                             2.2 aggressive and emotive attacks       0.44      0.37      0.40       141\n",
      "        2.3 dehumanising attacks & overt sexual objectification       0.26      0.22      0.24        41\n",
      "     3.1 casual use of gendered slurs, profanities, and insults       0.46      0.53      0.49       128\n",
      "        3.2 immutable gender differences and gender stereotypes       0.28      0.26      0.27        77\n",
      "                            3.3 backhanded gendered compliments       0.00      0.00      0.00        15\n",
      "             3.4 condescending explanations or unwelcome advice       0.00      0.00      0.00        10\n",
      "                4.1 supporting mistreatment of individual women       0.11      0.15      0.13        13\n",
      "4.2 supporting systemic discrimination against women as a group       0.17      0.14      0.15        51\n",
      "\n",
      "                                                       accuracy                           0.36       680\n",
      "                                                      macro avg       0.22      0.23      0.23       680\n",
      "                                                   weighted avg       0.35      0.36      0.35       680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_clf = tree.DecisionTreeClassifier()\n",
    "dt_clf.fit(x_train_c, y_train_c)\n",
    "pred = dt_clf.predict(x_test_c)\n",
    "acc = accuracy_score(pred, y_test_c)\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_c, pred))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_c, pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result\", \"task_c_cls_report_decision_tree.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VYczMOU59_D"
   },
   "source": [
    "**Xgboost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_c_enc = le.fit_transform(y_train_c)\n",
    "y_test_c_enc = le.fit_transform(y_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "JXnUe1qYeJUr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 41.32%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.47      0.29      0.36        56\n",
      "           2       0.41      0.64      0.50       139\n",
      "           3       0.45      0.41      0.43       141\n",
      "           4       0.40      0.20      0.26        41\n",
      "           5       0.43      0.60      0.50       128\n",
      "           6       0.38      0.31      0.34        77\n",
      "           7       0.00      0.00      0.00        15\n",
      "           8       0.00      0.00      0.00        10\n",
      "           9       0.29      0.15      0.20        13\n",
      "          10       0.28      0.14      0.18        51\n",
      "\n",
      "    accuracy                           0.41       680\n",
      "   macro avg       0.28      0.25      0.25       680\n",
      "weighted avg       0.39      0.41      0.39       680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=2)\n",
    "xgb_model.fit(x_train_c, y_train_c_enc)\n",
    "\n",
    "y_pred = xgb_model.predict(x_test_c)\n",
    "y_pred_enc = le.fit_transform(y_pred)\n",
    "\n",
    "acc = accuracy_score(y_pred_enc, y_test_c_enc)\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_c_enc, y_pred_enc))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_c_enc, y_pred_enc, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result\", \"task_c_cls_report_xgboost.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5OYIzAN6C5G"
   },
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "crkM6u3rrWmP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34.85%\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm       0.00      0.00      0.00         9\n",
      "                       1.2 incitement and encouragement of harm       0.00      0.00      0.00        56\n",
      "                                        2.1 descriptive attacks       0.29      0.94      0.44       139\n",
      "                             2.2 aggressive and emotive attacks       0.46      0.36      0.40       141\n",
      "        2.3 dehumanising attacks & overt sexual objectification       0.00      0.00      0.00        41\n",
      "     3.1 casual use of gendered slurs, profanities, and insults       0.50      0.43      0.46       128\n",
      "        3.2 immutable gender differences and gender stereotypes       0.00      0.00      0.00        77\n",
      "                            3.3 backhanded gendered compliments       0.00      0.00      0.00        15\n",
      "             3.4 condescending explanations or unwelcome advice       0.00      0.00      0.00        10\n",
      "                4.1 supporting mistreatment of individual women       0.00      0.00      0.00        13\n",
      "4.2 supporting systemic discrimination against women as a group       0.00      0.00      0.00        51\n",
      "\n",
      "                                                       accuracy                           0.35       680\n",
      "                                                      macro avg       0.11      0.16      0.12       680\n",
      "                                                   weighted avg       0.25      0.35      0.26       680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(max_depth=10, random_state=2).fit(x_train_c, y_train_c)\n",
    "rf_pred = rf_clf.predict(x_test_c)\n",
    "acc = accuracy_score(rf_pred, y_test_c)\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_c, rf_pred))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_c, pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result\", \"task_c_cls_report_random_forest.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
